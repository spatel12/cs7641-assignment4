{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solving FrozenLake8x8 environment using Policy iteration.\n",
    "Author : Moustafa Alzantot (malzantot@ucla.edu)\n",
    "Citation: https://medium.com/@m.alzantot/deep-reinforcement-learning-demysitifed-episode-2-policy-iteration-value-iteration-and-q-978f9e89ddaa\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "import time as time\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def run_episode(env, policy, gamma = 1.0, render = False):\n",
    "    \"\"\" Runs an episode and return the total reward \"\"\"\n",
    "    obs = env.reset()\n",
    "    total_reward = 0\n",
    "    step_idx = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        obs, reward, done , _ = env.step(int(policy[obs]))\n",
    "        total_reward += (gamma ** step_idx * reward)\n",
    "        step_idx += 1\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy, gamma = 1.0, n = 1000):\n",
    "    scores = [run_episode(env, policy, gamma, False) for _ in range(n)]\n",
    "    return scores\n",
    "\n",
    "def extract_policy(v, gamma = 1.0):\n",
    "    \"\"\" Extract the policy given a value-function \"\"\"\n",
    "    policy = np.zeros(env.nS)\n",
    "    for s in range(env.nS):\n",
    "        q_sa = np.zeros(env.nA)\n",
    "        for a in range(env.nA):\n",
    "            q_sa[a] = sum([p * (r + gamma * v[s_]) for p, s_, r, _ in  env.P[s][a]])\n",
    "        policy[s] = np.argmax(q_sa)\n",
    "    return policy\n",
    "\n",
    "def compute_policy_v(env, policy, gamma=1.0):\n",
    "    \"\"\" Iteratively evaluate the value-function under policy.\n",
    "    Alternatively, we could formulate a set of linear equations in iterms of v[s] \n",
    "    and solve them to find the value function.\n",
    "    \"\"\"\n",
    "    v = np.zeros(env.nS)\n",
    "    eps = 1e-10\n",
    "    #eps=0.1\n",
    "    while True:\n",
    "        prev_v = np.copy(v)\n",
    "        for s in range(env.nS):\n",
    "            policy_a = policy[s]\n",
    "            v[s] = sum([p * (r + gamma * prev_v[s_]) for p, s_, r, _ in env.P[s][policy_a]])\n",
    "        if (np.sum((np.fabs(prev_v - v))) <= eps):\n",
    "            # value converged\n",
    "            break\n",
    "    return v\n",
    "\n",
    "def policy_iteration(env, gamma = 1.0):\n",
    "    \"\"\" Policy-Iteration algorithm \"\"\"\n",
    "    policy = np.random.choice(env.nA, size=(env.nS))  # initialize a random policy\n",
    "    max_iterations = 3000\n",
    "    gamma = 1.0\n",
    "    for i in range(max_iterations):\n",
    "        old_policy_v = compute_policy_v(env, policy, gamma)\n",
    "        new_policy = extract_policy(old_policy_v, gamma)\n",
    "        if (np.all(policy == new_policy)):\n",
    "            print ('Policy-Iteration converged at step %d.' %(i+1))\n",
    "            break\n",
    "        policy = new_policy\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy-Iteration converged at step 8.\n",
      "Average scores =  1.0001000000000016e-134\n",
      "Policy-Iteration converged at step 8.\n",
      "Average scores =  1.0000000000000005e-74\n",
      "Policy-Iteration converged at step 13.\n",
      "Average scores =  1.0000010001000004e-50\n",
      "Policy-Iteration converged at step 12.\n",
      "Average scores =  1.0001110102110014e-30\n",
      "Policy-Iteration converged at step 12.\n",
      "Average scores =  1.691250748631779e-19\n",
      "Policy-Iteration converged at step 6.\n",
      "Average scores =  4.929682217155372e-15\n",
      "Policy-Iteration converged at step 13.\n",
      "Average scores =  5.000545675700211e-05\n",
      "Policy-Iteration converged at step 7.\n",
      "Average scores =  0.89\n"
     ]
    }
   ],
   "source": [
    "gammas = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.4, 0.8, 1.0]\n",
    "\n",
    "for gamma in gammas:\n",
    "    env_name  = 'FrozenLake8x8-v0'\n",
    "    env = gym.make(env_name)\n",
    "    optimal_policy = policy_iteration(env, gamma = gamma)\n",
    "    scores = evaluate_policy(env, optimal_policy, gamma = gamma)\n",
    "    print('Average scores = ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many iterations does it take to converge?\n",
    "# 8\n",
    "\n",
    "# How did you choose to define convergence?\n",
    "# When the new policy is equivalent to the old policy\n",
    "\n",
    "\n",
    "# episilon = 1e-10, which means that there is a low chance of selecting a random action instead of the desired action\n",
    "# The reward for falling into the hole ends the game\n",
    "\n",
    "# How did the number of states affect things, if at all?\n",
    "# 4x4=16 states vs 8x8=64 states\n",
    "# Clock Time: 0.249 seconds, 3.564 seconds\n",
    "# Policy average score: 0.72, 0.89\n",
    "# Iterations to value iteration convergence: 6, 8\n",
    "# Total Reward: 1.0, 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy-Iteration converged at step 13.\n",
      "Average time: 5.210411071777344\n",
      "Average scores =  0.887\n"
     ]
    }
   ],
   "source": [
    "env_name  = 'FrozenLake8x8-v0'\n",
    "env = gym.make(env_name)\n",
    "start = time.time()\n",
    "optimal_policy = policy_iteration(env, gamma = 1.0)\n",
    "print(\"Average time: \" + str(((time.time() - start))))\n",
    "scores = evaluate_policy(env, optimal_policy, gamma = 1.0)\n",
    "print('Average scores = ', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Reward')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(scores)\n",
    "plt.title(\"Distribution of Rewards (Frozen Lake - Policy Iteration)\")\n",
    "plt.xlabel(\"Reward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
